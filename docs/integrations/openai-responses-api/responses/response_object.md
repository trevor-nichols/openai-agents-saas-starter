## The response object

-   **`background`** *boolean*
    Whether the model response ran in the background.

-   **`conversation`** *object*
    The conversation that this response belongs to.
    -   **`id`** *string*
        The unique ID of the conversation.

-   **`created_at`** *number*
    Unix timestamp (in seconds) of when this Response was created.

-   **`error`** *object*
    An error object returned when the model fails to generate a Response.
    -   **`code`** *string*
        The error code for the response.
    -   **`message`** *string*
        A human-readable description of the error.

-   **`id`** *string*
    Unique identifier for this Response.

-   **`incomplete_details`** *object*
    Details about why the response is incomplete.
    -   **`reason`** *string*
        The reason why the response is incomplete.

-   **`instructions`** *string or array*
    A system (or developer) message inserted into the model's context.
    *(See `input` parameter in "Create a model response" for detailed structure.)*

-   **`max_output_tokens`** *integer*
    An upper bound for the number of tokens that can be generated.

-   **`max_tool_calls`** *integer*
    The maximum number of total calls to built-in tools that can be processed.

-   **`metadata`** *map*
    Set of 16 key-value pairs attached to the object.

-   **`model`** *string*
    Model ID used to generate the response.

-   **`object`** *string*
    The object type, always `response`.

-   **`output`** *array*
    An array of content items generated by the model.
    *(See `Item` object in "Create a model response" for detailed structure.)*

-   **`output_text`** *string* `SDK Only`
    SDK-only convenience property that contains the aggregated text output from all `output_text` items in the `output` array.

-   **`parallel_tool_calls`** *boolean*
    Whether the model was allowed to run tool calls in parallel.

-   **`previous_response_id`** *string*
    The unique ID of the previous response to the model.

-   **`prompt`** *object*
    Reference to a prompt template and its variables.
    -   **`id`** *string*
    -   **`variables`** *map* `Optional`
    -   **`version`** *string* `Optional`

-   **`prompt_cache_key`** *string*
    Used by OpenAI to cache responses for similar requests.

-   **`prompt_cache_retention`** *string*
    The retention policy for the prompt cache.

-   **`reasoning`** *object*
    Configuration options for reasoning models.
    -   **`effort`** *string*
    -   **`generate_summary`** *string* `Deprecated`
    -   **`summary`** *string*

-   **`safety_identifier`** *string*
    A stable identifier for your application's users.

-   **`service_tier`** *string*
    Specifies the processing type used for serving the request.

-   **`status`** *string*
    The status of the response generation (`completed`, `failed`, `in_progress`, `cancelled`, `queued`, or `incomplete`).

-   **`temperature`** *number*
    The sampling temperature used.

-   **`text`** *object*
    Configuration options for a text response.
    *(See `text` parameter in "Create a model response" for detailed structure.)*

-   **`tool_choice`** *string or object*
    How the model selected which tool to use.
    *(See `tool_choice` parameter in "Create a model response" for detailed structure.)*

-   **`tools`** *array*
    An array of tools the model was able to call.
    *(See `tools` parameter in "Create a model response" for detailed structure.)*

-   **`top_logprobs`** *integer*
    The number of most likely tokens returned at each token position.

-   **`top_p`** *number*
    The nucleus sampling value used.

-   **`truncation`** *string*
    The truncation strategy used.

-   **`usage`** *object*
    Token usage details.
    -   **`input_tokens`** *integer*
    -   **`input_tokens_details`** *object*
        -   **`cached_tokens`** *integer*
    -   **`output_tokens`** *integer*
    -   **`output_tokens_details`** *object*
        -   **`reasoning_tokens`** *integer*
    -   **`total_tokens`** *integer*

-   **`user`** *string* `Deprecated`
    A stable identifier for your end-users.

### OBJECT The response object

```json
{
  "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
  "object": "response",
  "created_at": 1741476777,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-4o-2024-08-06",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 328,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 52,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 380
  },
  "user": null,
  "metadata": {}
}
```

---

