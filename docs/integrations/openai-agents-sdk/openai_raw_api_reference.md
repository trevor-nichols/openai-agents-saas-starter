# OpenAI Responses API
Create a model response
post
 
https://api.openai.com/v1/responses
Creates a model response. Provide text or image inputs to generate text or JSON outputs. Have the model call your own custom code or use built-in tools like web search or file search to use your own data as input for the model's response.

Request body
background
boolean

Optional
Defaults to false
Whether to run the model response in the background. Learn more.

conversation
string or object

Optional
Defaults to null
The conversation that this response belongs to. Items from this conversation are prepended to input_items for this response request. Input items and output items from this response are automatically added to this conversation after this response completes.


Hide possible types
Conversation ID
string
The unique ID of the conversation.

Conversation object
object
The conversation that this response belongs to.


Hide properties
id
string

Required
The unique ID of the conversation.

include
array

Optional
Specify additional output data to include in the model response. Currently supported values are:

web_search_call.action.sources: Include the sources of the web search tool call.
code_interpreter_call.outputs: Includes the outputs of python code execution in code interpreter tool call items.
computer_call_output.output.image_url: Include image urls from the computer call output.
file_search_call.results: Include the search results of the file search tool call.
message.input_image.image_url: Include image urls from the input message.
message.output_text.logprobs: Include logprobs with assistant messages.
reasoning.encrypted_content: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the store parameter is set to false, or when an organization is enrolled in the zero data retention program).
input
string or array

Optional
Text, image, or file inputs to the model, used to generate a response.

Learn more:

Text inputs and outputs
Image inputs
File inputs
Conversation state
Function calling

Hide possible types
Text input
string
A text input to the model, equivalent to a text input with the user role.

Input item list
array
A list of one or many input items to the model, containing different content types.


Hide possible types
Input message
object
A message input to the model with a role indicating instruction following hierarchy. Instructions given with the developer or system role take precedence over instructions given with the user role. Messages with the assistant role are presumed to have been generated by the model in previous interactions.


Hide properties
content
string or array

Required
Text, image, or audio input to the model, used to generate a response. Can also contain previous assistant responses.


Hide possible types
Text input
string
A text input to the model.

Input item content list
array
A list of one or many input items to the model, containing different content types.


Hide possible types
Input text
object
A text input to the model.


Hide properties
text
string

Required
The text input to the model.

type
string

Required
The type of the input item. Always input_text.

Input image
object
An image input to the model. Learn about image inputs.


Hide properties
detail
string

Required
The detail level of the image to be sent to the model. One of high, low, or auto. Defaults to auto.

type
string

Required
The type of the input item. Always input_image.

file_id
string

Optional
The ID of the file to be sent to the model.

image_url
string

Optional
The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.

Input file
object
A file input to the model.


Hide properties
type
string

Required
The type of the input item. Always input_file.

file_data
string

Optional
The content of the file to be sent to the model.

file_id
string

Optional
The ID of the file to be sent to the model.

file_url
string

Optional
The URL of the file to be sent to the model.

filename
string

Optional
The name of the file to be sent to the model.

Input audio
object
An audio input to the model.


Hide properties
input_audio
object

Required

Hide properties
data
string

Required
Base64-encoded audio data.

format
string

Required
The format of the audio data. Currently supported formats are mp3 and wav.

type
string

Required
The type of the input item. Always input_audio.

role
string

Required
The role of the message input. One of user, assistant, system, or developer.

type
string

Optional
The type of the message input. Always message.

Item
object
An item representing part of the context for the response to be generated by the model. Can contain text, images, and audio inputs, as well as previous assistant responses and tool call outputs.


Hide possible types
Input message
object
A message input to the model with a role indicating instruction following hierarchy. Instructions given with the developer or system role take precedence over instructions given with the user role.


Hide properties
content
array

Required
A list of one or many input items to the model, containing different content types.


Hide possible types
Input text
object
A text input to the model.


Hide properties
text
string

Required
The text input to the model.

type
string

Required
The type of the input item. Always input_text.

Input image
object
An image input to the model. Learn about image inputs.


Hide properties
detail
string

Required
The detail level of the image to be sent to the model. One of high, low, or auto. Defaults to auto.

type
string

Required
The type of the input item. Always input_image.

file_id
string

Optional
The ID of the file to be sent to the model.

image_url
string

Optional
The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.

Input file
object
A file input to the model.


Hide properties
type
string

Required
The type of the input item. Always input_file.

file_data
string

Optional
The content of the file to be sent to the model.

file_id
string

Optional
The ID of the file to be sent to the model.

file_url
string

Optional
The URL of the file to be sent to the model.

filename
string

Optional
The name of the file to be sent to the model.

Input audio
object
An audio input to the model.


Hide properties
input_audio
object

Required

Hide properties
data
string

Required
Base64-encoded audio data.

format
string

Required
The format of the audio data. Currently supported formats are mp3 and wav.

type
string

Required
The type of the input item. Always input_audio.

role
string

Required
The role of the message input. One of user, system, or developer.

status
string

Optional
The status of item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

type
string

Optional
The type of the message input. Always set to message.

Output message
object
An output message from the model.


Hide properties
content
array

Required
The content of the output message.


Hide possible types
Output text
object
A text output from the model.


Hide properties
annotations
array

Required
The annotations of the text output.


Hide possible types
File citation
object
A citation to a file.


Hide properties
file_id
string

Required
The ID of the file.

filename
string

Required
The filename of the file cited.

index
integer

Required
The index of the file in the list of files.

type
string

Required
The type of the file citation. Always file_citation.

URL citation
object
A citation for a web resource used to generate a model response.


Hide properties
end_index
integer

Required
The index of the last character of the URL citation in the message.

start_index
integer

Required
The index of the first character of the URL citation in the message.

title
string

Required
The title of the web resource.

type
string

Required
The type of the URL citation. Always url_citation.

url
string

Required
The URL of the web resource.

Container file citation
object
A citation for a container file used to generate a model response.


Hide properties
container_id
string

Required
The ID of the container file.

end_index
integer

Required
The index of the last character of the container file citation in the message.

file_id
string

Required
The ID of the file.

filename
string

Required
The filename of the container file cited.

start_index
integer

Required
The index of the first character of the container file citation in the message.

type
string

Required
The type of the container file citation. Always container_file_citation.

File path
object
A path to a file.


Hide properties
file_id
string

Required
The ID of the file.

index
integer

Required
The index of the file in the list of files.

type
string

Required
The type of the file path. Always file_path.

text
string

Required
The text output from the model.

type
string

Required
The type of the output text. Always output_text.

logprobs
array

Optional

Show properties
Refusal
object
A refusal from the model.


Hide properties
refusal
string

Required
The refusal explanation from the model.

type
string

Required
The type of the refusal. Always refusal.

id
string

Required
The unique ID of the output message.

role
string

Required
The role of the output message. Always assistant.

status
string

Required
The status of the message input. One of in_progress, completed, or incomplete. Populated when input items are returned via API.

type
string

Required
The type of the output message. Always message.

File search tool call
object
The results of a file search tool call. See the file search guide for more information.


Show properties
Computer tool call
object
A tool call to a computer use tool. See the computer use guide for more information.


Show properties
Computer tool call output
object
The output of a computer tool call.


Show properties
Web search tool call
object
The results of a web search tool call. See the web search guide for more information.


Show properties
Function tool call
object
A tool call to run a function. See the function calling guide for more information.


Hide properties
arguments
string

Required
A JSON string of the arguments to pass to the function.

call_id
string

Required
The unique ID of the function tool call generated by the model.

name
string

Required
The name of the function to run.

type
string

Required
The type of the function tool call. Always function_call.

id
string

Optional
The unique ID of the function tool call.

status
string

Optional
The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Function tool call output
object
The output of a function tool call.


Hide properties
call_id
string

Required
The unique ID of the function tool call generated by the model.

output
string or array

Required
Text, image, or file output of the function tool call.


Hide possible types
string
A JSON string of the output of the function tool call.

array

Hide possible types
Input text
object
A text input to the model.


Hide properties
text
string

Required
The text input to the model.

type
string

Required
The type of the input item. Always input_text.

Input image
object
An image input to the model. Learn about image inputs


Hide properties
type
string

Required
The type of the input item. Always input_image.

detail
string

Optional
The detail level of the image to be sent to the model. One of high, low, or auto. Defaults to auto.

file_id
string

Optional
The ID of the file to be sent to the model.

image_url
string

Optional
The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.

Input file
object
A file input to the model.


Hide properties
type
string

Required
The type of the input item. Always input_file.

file_data
string

Optional
The base64-encoded data of the file to be sent to the model.

file_id
string

Optional
The ID of the file to be sent to the model.

file_url
string

Optional
The URL of the file to be sent to the model.

filename
string

Optional
The name of the file to be sent to the model.

type
string

Required
The type of the function tool call output. Always function_call_output.

id
string

Optional
The unique ID of the function tool call output. Populated when this item is returned via API.

status
string

Optional
The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Reasoning
object
A description of the chain of thought used by a reasoning model while generating a response. Be sure to include these items in your input to the Responses API for subsequent turns of a conversation if you are manually managing context.


Hide properties
id
string

Required
The unique identifier of the reasoning content.

summary
array

Required
Reasoning summary content.


Hide properties
text
string

Required
A summary of the reasoning output from the model so far.

type
string

Required
The type of the object. Always summary_text.

type
string

Required
The type of the object. Always reasoning.

content
array

Optional
Reasoning text content.


Hide properties
text
string

Required
The reasoning text from the model.

type
string

Required
The type of the reasoning text. Always reasoning_text.

encrypted_content
string

Optional
The encrypted content of the reasoning item - populated when a response is generated with reasoning.encrypted_content in the include parameter.

status
string

Optional
The status of the item. One of in_progress, completed, or incomplete. Populated when items are returned via API.

Image generation call
object
An image generation request made by the model.


Hide properties
id
string

Required
The unique ID of the image generation call.

result
string

Required
The generated image encoded in base64.

status
string

Required
The status of the image generation call.

type
string

Required
The type of the image generation call. Always image_generation_call.

Code interpreter tool call
object
A tool call to run code.


Show properties
Local shell call
object
A tool call to run a command on the local shell.


Hide properties
action
object

Required
Execute a shell command on the server.


Hide properties
command
array

Required
The command to run.

env
object

Required
Environment variables to set for the command.

type
string

Required
The type of the local shell action. Always exec.

timeout_ms
integer

Optional
Optional timeout in milliseconds for the command.

user
string

Optional
Optional user to run the command as.

working_directory
string

Optional
Optional working directory to run the command in.

call_id
string

Required
The unique ID of the local shell tool call generated by the model.

id
string

Required
The unique ID of the local shell call.

status
string

Required
The status of the local shell call.

type
string

Required
The type of the local shell call. Always local_shell_call.

Local shell call output
object
The output of a local shell tool call.


Hide properties
id
string

Required
The unique ID of the local shell tool call generated by the model.

output
string

Required
A JSON string of the output of the local shell tool call.

type
string

Required
The type of the local shell tool call output. Always local_shell_call_output.

status
string

Optional
The status of the item. One of in_progress, completed, or incomplete.

MCP list tools
object
A list of tools available on an MCP server.


Hide properties
id
string

Required
The unique ID of the list.

server_label
string

Required
The label of the MCP server.

tools
array

Required
The tools available on the server.


Hide properties
input_schema
object

Required
The JSON schema describing the tool's input.

name
string

Required
The name of the tool.

annotations
object

Optional
Additional annotations about the tool.

description
string

Optional
The description of the tool.

type
string

Required
The type of the item. Always mcp_list_tools.

error
string

Optional
Error message if the server could not list tools.

MCP approval request
object
A request for human approval of a tool invocation.


Hide properties
arguments
string

Required
A JSON string of arguments for the tool.

id
string

Required
The unique ID of the approval request.

name
string

Required
The name of the tool to run.

server_label
string

Required
The label of the MCP server making the request.

type
string

Required
The type of the item. Always mcp_approval_request.

MCP approval response
object
A response to an MCP approval request.


Hide properties
approval_request_id
string

Required
The ID of the approval request being answered.

approve
boolean

Required
Whether the request was approved.

type
string

Required
The type of the item. Always mcp_approval_response.

id
string

Optional
The unique ID of the approval response

reason
string

Optional
Optional reason for the decision.

MCP tool call
object
An invocation of a tool on an MCP server.


Hide properties
arguments
string

Required
A JSON string of the arguments passed to the tool.

id
string

Required
The unique ID of the tool call.

name
string

Required
The name of the tool that was run.

server_label
string

Required
The label of the MCP server running the tool.

type
string

Required
The type of the item. Always mcp_call.

approval_request_id
string

Optional
Unique identifier for the MCP tool call approval request. Include this value in a subsequent mcp_approval_response input to approve or reject the corresponding tool call.

error
string

Optional
The error from the tool call, if any.

output
string

Optional
The output from the tool call.

status
string

Optional
The status of the tool call. One of in_progress, completed, incomplete, calling, or failed.

Custom tool call output
object
The output of a custom tool call from your code, being sent back to the model.


Hide properties
call_id
string

Required
The call ID, used to map this custom tool call output to a custom tool call.

output
string or array

Required
The output from the custom tool call generated by your code. Can be a string or an list of output content.


Show possible types
type
string

Required
The type of the custom tool call output. Always custom_tool_call_output.

id
string

Optional
The unique ID of the custom tool call output in the OpenAI platform.

Custom tool call
object
A call to a custom tool created by the model.


Hide properties
call_id
string

Required
An identifier used to map this custom tool call to a tool call output.

input
string

Required
The input for the custom tool call generated by the model.

name
string

Required
The name of the custom tool being called.

type
string

Required
The type of the custom tool call. Always custom_tool_call.

id
string

Optional
The unique ID of the custom tool call in the OpenAI platform.

Item reference
object
An internal identifier for an item to reference.


Hide properties
id
string

Required
The ID of the item to reference.

type
string

Optional
Defaults to item_reference
The type of item to reference. Always item_reference.

instructions
string

Optional
A system (or developer) message inserted into the model's context.

When using along with previous_response_id, the instructions from a previous response will not be carried over to the next response. This makes it simple to swap out system (or developer) messages in new responses.

max_output_tokens
integer

Optional
An upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.

max_tool_calls
integer

Optional
The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.

metadata
map

Optional
Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

model
string

Optional
Model ID used to generate the response, like gpt-5. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.

parallel_tool_calls
boolean

Optional
Defaults to true
Whether to allow the model to run tool calls in parallel.

previous_response_id
string

Optional
The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about conversation state. Cannot be used in conjunction with conversation.

prompt
object

Optional
Reference to a prompt template and its variables. Learn more.


Hide properties
id
string

Required
The unique identifier of the prompt template to use.

variables
map

Optional
Optional map of values to substitute in for variables in your prompt. The substitution values can either be strings, or other Response input types like images or files.

version
string

Optional
Optional version of the prompt template.

prompt_cache_key
string

Optional
Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the user field. Learn more.

reasoning
object

Optional
gpt-5.1 and o-series models only

Configuration options for reasoning models.


Hide properties
effort
string

Optional
Defaults to medium
Constrains effort on reasoning for reasoning models. Currently supported values are minimal, low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.

Note: The gpt-5-pro model defaults to (and only supports) high reasoning effort.

generate_summary
Deprecated
string

Optional
Deprecated: use summary instead.

A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

summary
string

Optional
A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.

safety_identifier
string

Optional
A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should be a string that uniquely identifies each user. We recommend hashing their username or email address, in order to avoid sending us any identifying information. Learn more.

service_tier
string

Optional
Defaults to auto
Specifies the processing type used for serving the request.

If set to 'auto', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use 'default'.
If set to 'default', then the request will be processed with the standard pricing and performance for the selected model.
If set to 'flex' or 'priority', then the request will be processed with the corresponding service tier.
When not set, the default behavior is 'auto'.
When the service_tier parameter is set, the response body will include the service_tier value based on the processing mode actually used to serve the request. This response value may be different from the value set in the parameter.

store
boolean

Optional
Defaults to true
Whether to store the generated model response for later retrieval via API.

stream
boolean

Optional
Defaults to false
If set to true, the model response data will be streamed to the client as it is generated using server-sent events. See the Streaming section below for more information.

stream_options
object

Optional
Defaults to null
Options for streaming responses. Only set this when you set stream: true.


Hide properties
include_obfuscation
boolean

Optional
When true, stream obfuscation will be enabled. Stream obfuscation adds random characters to an obfuscation field on streaming delta events to normalize payload sizes as a mitigation to certain side-channel attacks. These obfuscation fields are included by default, but add a small amount of overhead to the data stream. You can set include_obfuscation to false to optimize for bandwidth if you trust the network links between your application and the OpenAI API.

temperature
number

Optional
Defaults to 1
What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.

text
object

Optional
Configuration options for a text response from the model. Can be plain text or structured JSON data. Learn more:

Text inputs and outputs
Structured Outputs

Hide properties
format
object

Optional
An object specifying the format that the model must output.

Configuring { "type": "json_schema" } enables Structured Outputs, which ensures the model will match your supplied JSON schema. Learn more in the Structured Outputs guide.

The default format is { "type": "text" } with no additional options.

Not recommended for gpt-4o and newer models:

Setting to { "type": "json_object" } enables the older JSON mode, which ensures the message the model generates is valid JSON. Using json_schema is preferred for models that support it.


Hide possible types
Text
object
Default response format. Used to generate text responses.


Show properties
JSON schema
object
JSON Schema response format. Used to generate structured JSON responses. Learn more about Structured Outputs.


Hide properties
name
string

Required
The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.

schema
object

Required
The schema for the response format, described as a JSON Schema object. Learn how to build JSON schemas here.

type
string

Required
The type of response format being defined. Always json_schema.

description
string

Optional
A description of what the response format is for, used by the model to determine how to respond in the format.

strict
boolean

Optional
Defaults to false
Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true. To learn more, read the Structured Outputs guide.

JSON object
object
JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so.


Hide properties
type
string

Required
The type of response format being defined. Always json_object.

verbosity
string

Optional
Defaults to medium
Constrains the verbosity of the model's response. Lower values will result in more concise responses, while higher values will result in more verbose responses. Currently supported values are low, medium, and high.

tool_choice
string or object

Optional
How the model should select which tool (or tools) to use when generating a response. See the tools parameter to see how to specify which tools the model can call.


Hide possible types
Tool choice mode
string
Controls which (if any) tool is called by the model.

none means the model will not call any tool and instead generates a message.

auto means the model can pick between generating a message or calling one or more tools.

required means the model must call one or more tools.

Allowed tools
object
Constrains the tools available to the model to a pre-defined set.


Hide properties
mode
string

Required
Constrains the tools available to the model to a pre-defined set.

auto allows the model to pick from among the allowed tools and generate a message.

required requires the model to call one or more of the allowed tools.

tools
array

Required
A list of tool definitions that the model should be allowed to call.

For the Responses API, the list of tool definitions might look like:

[
  { "type": "function", "name": "get_weather" },
  { "type": "mcp", "server_label": "deepwiki" },
  { "type": "image_generation" }
]

Hide properties
type
string

Required
Allowed tool configuration type. Always allowed_tools.

Hosted tool
object
Indicates that the model should use a built-in tool to generate a response. Learn more about built-in tools.


Show properties
Function tool
object
Use this option to force the model to call a specific function.


Show properties
MCP tool
object
Use this option to force the model to call a specific tool on a remote MCP server.


Show properties
Custom tool
object
Use this option to force the model to call a specific custom tool.


Show properties
tools
array

Optional
An array of tools the model may call while generating a response. You can specify which tool to use by setting the tool_choice parameter.

We support the following categories of tools:

Built-in tools: Tools that are provided by OpenAI that extend the model's capabilities, like web search or file search. Learn more about built-in tools.
MCP Tools: Integrations with third-party systems via custom MCP servers or predefined connectors such as Google Drive and SharePoint. Learn more about MCP Tools.
Function calls (custom tools): Functions that are defined by you, enabling the model to call your own code with strongly typed arguments and outputs. Learn more about function calling. You can also use custom tools to call your own code.

Hide possible types
Function
object
Defines a function in your own code the model can choose to call. Learn more about function calling.


Hide properties
name
string

Required
The name of the function to call.

parameters
object

Required
A JSON schema object describing the parameters of the function.

strict
boolean

Required
Whether to enforce strict parameter validation. Default true.

type
string

Required
The type of the function tool. Always function.

description
string

Optional
A description of the function. Used by the model to determine whether or not to call the function.

File search
object
A tool that searches for relevant content from uploaded files. Learn more about the file search tool.


Show properties
Computer use preview
object
A tool that controls a virtual computer. Learn more about the computer tool.


Show properties
Web search
object
Search the Internet for sources related to the prompt. Learn more about the web search tool.


Show properties
MCP tool
object
Give the model access to additional tools via remote Model Context Protocol (MCP) servers. Learn more about MCP.


Hide properties
server_label
string

Required
A label for this MCP server, used to identify it in tool calls.

type
string

Required
The type of the MCP tool. Always mcp.

allowed_tools
array or object

Optional
List of allowed tool names or a filter object.


Show possible types
authorization
string

Optional
An OAuth access token that can be used with a remote MCP server, either with a custom MCP server URL or a service connector. Your application must handle the OAuth authorization flow and provide the token here.

connector_id
string

Optional
Identifier for service connectors, like those available in ChatGPT. One of server_url or connector_id must be provided. Learn more about service connectors here.

Currently supported connector_id values are:

Dropbox: connector_dropbox
Gmail: connector_gmail
Google Calendar: connector_googlecalendar
Google Drive: connector_googledrive
Microsoft Teams: connector_microsoftteams
Outlook Calendar: connector_outlookcalendar
Outlook Email: connector_outlookemail
SharePoint: connector_sharepoint
headers
object

Optional
Optional HTTP headers to send to the MCP server. Use for authentication or other purposes.

require_approval
object or string

Optional
Defaults to always
Specify which of the MCP server's tools require approval.


Show possible types
server_description
string

Optional
Optional description of the MCP server, used to provide more context.

server_url
string

Optional
The URL for the MCP server. One of server_url or connector_id must be provided.

Code interpreter
object
A tool that runs Python code to help generate a response to a prompt.


Show properties
Image generation tool
object
A tool that generates images using a model like gpt-image-1.


Show properties
Local shell tool
object
A tool that allows the model to execute shell commands in a local environment.


Hide properties
type
string

Required
The type of the local shell tool. Always local_shell.

Custom tool
object
A custom tool that processes input using a specified format. Learn more about custom tools.


Hide properties
name
string

Required
The name of the custom tool, used to identify it in tool calls.

type
string

Required
The type of the custom tool. Always custom.

description
string

Optional
Optional description of the custom tool, used to provide more context.

format
object

Optional
The input format for the custom tool. Default is unconstrained text.


Show possible types
Web search preview
object
This tool searches the web for relevant results to use in a response. Learn more about the web search tool.


Show properties
top_logprobs
integer

Optional
An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability.

top_p
number

Optional
Defaults to 1
An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

truncation
string

Optional
Defaults to disabled
The truncation strategy to use for the model response.

auto: If the input to this Response exceeds the model's context window size, the model will truncate the response to fit the context window by dropping items from the beginning of the conversation.
disabled (default): If the input size will exceed the context window size for a model, the request will fail with a 400 error.
user
Deprecated
string

Optional
This field is being replaced by safety_identifier and prompt_cache_key. Use prompt_cache_key instead to maintain caching optimizations. A stable identifier for your end-users. Used to boost cache hit rates by better bucketing similar requests and to help OpenAI detect and prevent abuse. Learn more.

Returns
Returns a Response object.

Text input
Image input
File input


Get a model response
get
 
https://api.openai.com/v1/responses/{response_id}
Retrieves a model response with the given ID.

Path parameters
response_id
string

Required
The ID of the response to retrieve.

Query parameters
include
array

Optional
Additional fields to include in the response. See the include parameter for Response creation above for more information.

include_obfuscation
boolean

Optional
When true, stream obfuscation will be enabled. Stream obfuscation adds random characters to an obfuscation field on streaming delta events to normalize payload sizes as a mitigation to certain side-channel attacks. These obfuscation fields are included by default, but add a small amount of overhead to the data stream. You can set include_obfuscation to false to optimize for bandwidth if you trust the network links between your application and the OpenAI API.

starting_after
integer

Optional
The sequence number of the event after which to start streaming.

stream
boolean

Optional
If set to true, the model response data will be streamed to the client as it is generated using server-sent events. See the Streaming section below for more information.

Returns
The Response object matching the specified ID.


# Reasoning
Example request
```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-5",
    input="How much wood would a woodchuck chuck?",
    reasoning={
        "effort": "high"
    }
)

print(response)
```
Response

```json
{
  "id": "resp_67ccd7eca01881908ff0b5146584e408072912b2993db808",
  "object": "response",
  "created_at": 1741477868,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-5",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd7f7b5848190a6f3e95d809f6b44072912b2993db808",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "The classic tongue twister...",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": "high",
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 81,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 1035,
    "output_tokens_details": {
      "reasoning_tokens": 832
    },
    "total_tokens": 1116
  },
  "user": null,
  "metadata": {}
}
```