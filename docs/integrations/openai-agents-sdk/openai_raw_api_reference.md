# OpenAI Responses API

## Create a model response
`POST` https://api.openai.com/v1/responses

Creates a model response. Provide text or image inputs to generate text or JSON outputs. Have the model call your own custom code or use built-in tools like web search or file search to use your own data as input for the model's response.

---

### Request body

*   `background` boolean _Optional_
    Defaults to `false`.
    Whether to run the model response in the background. Learn more.

*   `conversation` string or object _Optional_
    Defaults to `null`.
    The conversation that this response belongs to. Items from this conversation are prepended to `input_items` for this response request. Input items and output items from this response are automatically added to this conversation after this response completes.

    *Hide possible types*
    *   **Conversation ID** `string`
        The unique ID of the conversation.
    *   **Conversation object** `object`
        The conversation that this response belongs to.
        *Hide properties*
        *   `id` string _Required_
            The unique ID of the conversation.

*   `include` array _Optional_
    Specify additional output data to include in the model response. Currently supported values are:
    *   `web_search_call.action.sources`: Include the sources of the web search tool call.
    *   `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.
    *   `computer_call_output.output.image_url`: Include image urls from the computer call output.
    *   `file_search_call.results`: Include the search results of the file search tool call.
    *   `message.input_image.image_url`: Include image urls from the input message.
    *   `message.output_text.logprobs`: Include logprobs with assistant messages.
    *   `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the store parameter is set to `false`, or when an organization is enrolled in the zero data retention program).

*   `input` string or array _Optional_
    Text, image, or file inputs to the model, used to generate a response.
    Learn more:
    *   Text inputs and outputs
    *   Image inputs
    *   File inputs
    *   Conversation state
    *   Function calling

    *Hide possible types*
    *   **Text input** `string`
        A text input to the model, equivalent to a text input with the `user` role.
    *   **Input item list** `array`
        A list of one or many input items to the model, containing different content types.

        *Hide possible types*
        *   **Input message** `object`
            A message input to the model with a role indicating instruction following hierarchy. Instructions given with the `developer` or `system` role take precedence over instructions given with the `user` role. Messages with the `assistant` role are presumed to have been generated by the model in previous interactions.

            *Hide properties*
            *   `content` string or array _Required_
                Text, image, or audio input to the model, used to generate a response. Can also contain previous assistant responses.
                *Hide possible types*
                *   **Text input** `string`
                *   **Input item content list** `array`
                    *Hide possible types*
                    *   **Input text** `object`
                        *Hide properties*
                        *   `text` string _Required_
                        *   `type` string _Required_ (Always `input_text`)
                    *   **Input image** `object`
                        *Hide properties*
                        *   `detail` string _Required_ (One of `high`, `low`, or `auto`. Defaults to `auto`)
                        *   `type` string _Required_ (Always `input_image`)
                        *   `file_id` string _Optional_
                        *   `image_url` string _Optional_
                    *   **Input file** `object`
                        *Hide properties*
                        *   `type` string _Required_ (Always `input_file`)
                        *   `file_data` string _Optional_
                        *   `file_id` string _Optional_
                        *   `file_url` string _Optional_
                        *   `filename` string _Optional_
                    *   **Input audio** `object`
                        *Hide properties*
                        *   `input_audio` object _Required_
                            *Hide properties*
                            *   `data` string _Required_
                            *   `format` string _Required_ (Supported: `mp3`, `wav`)
                        *   `type` string _Required_ (Always `input_audio`)
            *   `role` string _Required_ (One of `user`, `assistant`, `system`, or `developer`)
            *   `type` string _Optional_ (Always `message`)
        *   **Item** `object`
            An item representing part of the context for the response to be generated by the model.
            *Hide possible types*
            *   **Input message** `object`
            *   **Output message** `object`
            *   **File search tool call** `object`
            *   **Computer tool call** `object`
            *   **Computer tool call output** `object`
            *   **Web search tool call** `object`
            *   **Function tool call** `object`
            *   **Function tool call output** `object`
            *   **Reasoning** `object`
            *   **Image generation call** `object`
            *   **Code interpreter tool call** `object`
            *   **Local shell call** `object`
            *   **Local shell call output** `object`
            *   **MCP list tools** `object`
            *   **MCP approval request** `object`
            *   **MCP approval response** `object`
            *   **MCP tool call** `object`
            *   **Custom tool call output** `object`
            *   **Custom tool call** `object`
            *   **Item reference** `object`

*   `instructions` string _Optional_
    A system (or developer) message inserted into the model's context.

*   `max_output_tokens` integer _Optional_
    An upper bound for the number of tokens that can be generated for a response.

*   `max_tool_calls` integer _Optional_
    The maximum number of total calls to built-in tools that can be processed in a response.

*   `metadata` map _Optional_
    Set of 16 key-value pairs that can be attached to an object.

*   `model` string _Optional_
    Model ID used to generate the response, like `gpt-5`.

*   `parallel_tool_calls` boolean _Optional_
    Defaults to `true`. Whether to allow the model to run tool calls in parallel.

*   `previous_response_id` string _Optional_
    The unique ID of the previous response to the model.

*   `prompt` object _Optional_
    Reference to a prompt template and its variables.
    *Hide properties*
    *   `id` string _Required_
    *   `variables` map _Optional_
    *   `version` string _Optional_

*   `prompt_cache_key` string _Optional_
    Used by OpenAI to cache responses for similar requests to optimize your cache hit rates.

*   `reasoning` object _Optional_
    (`gpt-5.1` and `o-series` models only) Configuration options for reasoning models.
    *Hide properties*
    *   `effort` string _Optional_ (Defaults to `medium`. Supported: `minimal`, `low`, `medium`, `high`)
    *   `generate_summary` string _Optional_ _Deprecated_
    *   `summary` string _Optional_ (One of `auto`, `concise`, or `detailed`)

*   `safety_identifier` string _Optional_
    A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies.

*   `service_tier` string _Optional_
    Defaults to `auto`. Specifies the processing type used for serving the request.

*   `store` boolean _Optional_
    Defaults to `true`. Whether to store the generated model response for later retrieval via API.

*   `stream` boolean _Optional_
    Defaults to `false`. If set to true, the model response data will be streamed.

*   `stream_options` object _Optional_
    Defaults to `null`. Options for streaming responses.
    *Hide properties*
    *   `include_obfuscation` boolean _Optional_

*   `temperature` number _Optional_
    Defaults to `1`. Sampling temperature to use, between 0 and 2.

*   `text` object _Optional_
    Configuration options for a text response from the model.
    *Hide properties*
    *   `format` object _Optional_
        *Hide possible types*
        *   **Text** `object`
        *   **JSON schema** `object`
            *Hide properties*
            *   `name` string _Required_
            *   `schema` object _Required_
            *   `type` string _Required_ (Always `json_schema`)
            *   `description` string _Optional_
            *   `strict` boolean _Optional_ (Defaults to `false`)
        *   **JSON object** `object`
            *Hide properties*
            *   `type` string _Required_ (Always `json_object`)
    *   `verbosity` string _Optional_ (Defaults to `medium`. Supported: `low`, `medium`, `high`)

*   `tool_choice` string or object _Optional_
    How the model should select which tool(s) to use.
    *Hide possible types*
    *   **Tool choice mode** `string` (`none`, `auto`, `required`)
    *   **Allowed tools** `object`
        *Hide properties*
        *   `mode` string _Required_ (`auto`, `required`)
        *   `tools` array _Required_
        *   `type` string _Required_ (Always `allowed_tools`)
    *   **Hosted tool** `object`
    *   **Function tool** `object`
    *   **MCP tool** `object`
    *   **Custom tool** `object`

*   `tools` array _Optional_
    An array of tools the model may call while generating a response.
    *Hide possible types*
    *   **Function** `object`
    *   **File search** `object`
    *   **Computer use preview** `object`
    *   **Web search** `object`
    *   **MCP tool** `object`
    *   **Code interpreter** `object`
    *   **Image generation tool** `object`
    *   **Local shell tool** `object`
    *   **Custom tool** `object`
    *   **Web search preview** `object`

*   `top_logprobs` integer _Optional_
    An integer between 0 and 20.

*   `top_p` number _Optional_
    Defaults to `1`. An alternative to sampling with temperature.

*   `truncation` string _Optional_
    Defaults to `disabled`. The truncation strategy to use (`auto` or `disabled`).

*   `user` string _Optional_ _Deprecated_
    Replaced by `safety_identifier` and `prompt_cache_key`.

---

### Returns
Returns a Response object.

---
---

## Get a model response
`GET` https://api.openai.com/v1/responses/{response_id}

Retrieves a model response with the given ID.

---

### Path parameters
*   `response_id` string _Required_
    The ID of the response to retrieve.

### Query parameters
*   `include` array _Optional_
    Additional fields to include in the response.
*   `include_obfuscation` boolean _Optional_
    When `true`, stream obfuscation will be enabled.
*   `starting_after` integer _Optional_
    The sequence number of the event after which to start streaming.
*   `stream` boolean _Optional_
    If set to `true`, the model response data will be streamed.

---

### Returns
The Response object matching the specified ID.

---
---

# Reasoning

### Example request
```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-5",
    input="How much wood would a woodchuck chuck?",
    reasoning={
        "effort": "high"
    }
)

print(response)
```

### Response```json
{
  "id": "resp_67ccd7eca01881908ff0b5146584e408072912b2993db808",
  "object": "response",
  "created_at": 1741477868,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-5",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd7f7b5848190a6f3e95d809f6b44072912b2993db808",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "The classic tongue twister...",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": "high",
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 81,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 1035,
    "output_tokens_details": {
      "reasoning_tokens": 832
    },
    "total_tokens": 1116
  },
  "user": null,
  "metadata": {}
}
```